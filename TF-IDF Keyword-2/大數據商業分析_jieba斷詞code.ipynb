{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>編號</th>\n",
       "      <th>類別</th>\n",
       "      <th>時間</th>\n",
       "      <th>標題</th>\n",
       "      <th>內容</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>全部財經新聞</td>\n",
       "      <td>2016/1/1 0:05</td>\n",
       "      <td>外資2015年台股買超462億元 四年來最少</td>\n",
       "      <td>外資2015年在台股買超462億元，是四年來最少金額，但在亞股中已是買超最多的市場，使得外資...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>全部財經新聞</td>\n",
       "      <td>2016/1/1 0:24</td>\n",
       "      <td>菲人不論貧富 樂觀迎新年</td>\n",
       "      <td>菲律賓人在燦爛的煙火中迎接2016年，雖然慶祝規模不如其他國際大城，但歡樂氣氛不減，近9成民...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>全部財經新聞</td>\n",
       "      <td>2016/1/1 0:27</td>\n",
       "      <td>台北101煙火</td>\n",
       "      <td>台北101年煙火，施放3萬發璀璨的煙火氣勢磅礡，計有238秒為歷年之最，展現歡欣鼓舞的氣息，...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>全部財經新聞</td>\n",
       "      <td>2016/1/1 0:39</td>\n",
       "      <td>新年維安 法出動逾10萬警力</td>\n",
       "      <td>法國內政部長卡澤納夫（Bernard Cazeneuve）今天表示，全法各地將部署10萬名以...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>全部財經新聞</td>\n",
       "      <td>2016/1/1 0:41</td>\n",
       "      <td>驚豔！新港奉天宮百年大醮</td>\n",
       "      <td>倒數5、4、3、2、1「哇！好美啊！」，燦爛壯闊的高空煙火，照亮嘉義新港奉天宮百年建醮會場，...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   編號      類別             時間                      標題  \\\n",
       "0   1  全部財經新聞  2016/1/1 0:05  外資2015年台股買超462億元 四年來最少   \n",
       "1   2  全部財經新聞  2016/1/1 0:24            菲人不論貧富 樂觀迎新年   \n",
       "2   3  全部財經新聞  2016/1/1 0:27                 台北101煙火   \n",
       "3   4  全部財經新聞  2016/1/1 0:39          新年維安 法出動逾10萬警力   \n",
       "4   5  全部財經新聞  2016/1/1 0:41            驚豔！新港奉天宮百年大醮   \n",
       "\n",
       "                                                  內容  \n",
       "0  外資2015年在台股買超462億元，是四年來最少金額，但在亞股中已是買超最多的市場，使得外資...  \n",
       "1  菲律賓人在燦爛的煙火中迎接2016年，雖然慶祝規模不如其他國際大城，但歡樂氣氛不減，近9成民...  \n",
       "2  台北101年煙火，施放3萬發璀璨的煙火氣勢磅礡，計有238秒為歷年之最，展現歡欣鼓舞的氣息，...  \n",
       "3  法國內政部長卡澤納夫（Bernard Cazeneuve）今天表示，全法各地將部署10萬名以...  \n",
       "4  倒數5、4、3、2、1「哇！好美啊！」，燦爛壯闊的高空煙火，照亮嘉義新港奉天宮百年建醮會場，...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jieba\n",
    "import pandas as pd\n",
    "from urllib.parse import unquote\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "df = pd.DataFrame(pd.read_csv('Downloads/test.csv',low_memory=False))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "collections =pd.read_excel('Downloads/hw1_text.xlsx', index_col = 0)\n",
    "stopword = []\n",
    "n = len(collections)\n",
    "with open ('Downloads/stopwords.txt','r',encoding = 'utf-8') as file:\n",
    "    for data in file.readlines():\n",
    "        data = data.strip()\n",
    "        stopword.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6669\n",
      "652\n",
      "1941\n",
      "1736\n",
      "27118\n",
      "8232\n",
      "<class 'int'>\n",
      "CPU times: user 46.9 s, sys: 440 ms, total: 47.4 s\n",
      "Wall time: 48.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "index_list = {}\n",
    "topic = ['銀行','信用卡','匯率','台積電','台灣','日本']\n",
    "for i in range(len(topic)):\n",
    "    index_list[i] = []\n",
    "    for index, val in collections.iterrows(): # for 90000\n",
    "        if topic[i] in val[\"內容\"]:\n",
    "            index_list[i].append(index)\n",
    "for i in range(len(topic)):\n",
    "    print(len(index_list[i]))\n",
    "    \n",
    "print(type(index_list[0][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'preprocess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'preprocess' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "K = [2, 3, 4, 5, 6]\n",
    "_RTS = {}\n",
    "i = 0\n",
    "for index, val in collections.iterrows(): # for 90000\n",
    "    if index in index_list[1]:\n",
    "      _RTS[index] = []\n",
    "      for k in K:\n",
    "        _RTS[index].append(preprocess(val[\"標題\"]+val[\"內容\"],k,stopword))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6669\n",
      "3627292\n"
     ]
    }
   ],
   "source": [
    "##銀行\n",
    "from nltk.classify.megam import numpy\n",
    "array=numpy.array(index_list[0])\n",
    "#print(collections[array])\n",
    "a_1 = df.iloc[array,[3]]\n",
    "a_2 = df.iloc[array,[4]]\n",
    "#print(a_2)\n",
    "rr = a_2.iloc[3,0]\n",
    "print(len(index_list[0]))\n",
    "#print(type(str(a_1[5:6])))\n",
    "words = []\n",
    "words_2 = []\n",
    "for i in range(len(index_list[0])):\n",
    "#words = jieba.lcut(a , cut_all=False)\n",
    "    #words = jieba.lcut(str(a_2.iloc[i,0]) , cut_all=False)\n",
    "    #words_2 = jieba.lcut(str(a_1.iloc[i,0]) , cut_all=False)\n",
    "    words +=(jieba.lcut(str(a_2.iloc[i,0]) , cut_all=False))\n",
    "    words_2 +=(jieba.lcut(str(a_2.iloc[i,0]) , cut_all=False))\n",
    "ans_1 = words + words_2\n",
    "#for word in ans_1:\n",
    " #   print(word)\n",
    "print(len(ans_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['銀行', '大陸', '分行', '11', '月', '新增', '一筆', '600', '萬元', '的', '逾期', '放款', '使', '逾期', '放款', '比率', '提升', '至', '0.48%', '據', '了解', '發生', '逾', '放', '的', '是', '一家', '台資', '的', '工具', '機業者', '工廠', '設', '在', '上海', '對此', '台銀', '昨', '（', '31', '）', '日', '低調', '回應', '該筆', '放款', '出現', '一些', '問題', '基', '於', '審慎', '原則', '台銀', '按大陸', '監理', '機關', '的', '要求', '已經', '轉銷', '呆帳', '大陸', '曝險', '快速', '攀升', '但', '經濟', '下滑', '引發', '銀行', '放款', '恐出', '現逾放', '的', '風險', '去年', '以來', '持續', '是', '立法院', '關心', '的', '話題', '如', '2014', '年', '上半年', '的', '中國', '旭光', '高新', '企業', '倒帳', '九家', '台資', '銀行', '共', '借出', '1.1', '億', '美元', '；', '同年', '下半年', '爆出', '福建', '索力', '倒帳', '包括', '六家', '國銀', '在', '內', '的', '金融', '機構', '共', '借款', '000', '萬', '美元', '2015', '年則', '以', '七家', '我國', '銀行', '辦理', '聯貸', '的', '大', '陸漢能', '集團案', '最受', '矚目', '據', '了解', '目前', '金管會', '除緊', '盯', '國銀', '在', '大陸', '的', '授信', '情況', '也', '專案', '指示', '存保', '公司', '針對', '銀行', '大陸', '曝險', '情況', '加強', '監控', '有', '狀況', '就', '立即', '通報', '例如', '中國核', '工業', '集團', '、', '中國', '兵器', '工業', '集團', '在', '內', '的', '14', '家', '企業', '即', '曾', '被', '存保', '列入', '示警', '名單', '中', '美國', '司法部', '31', '日', '表示', '一名', '25', '歲', '男子', '計畫', '在', '除夕夜', '攻擊', '紐約州羅徹', '斯特', '市', '一家', '餐廳', '已', '遭到', '聯邦', '調查局', '（', 'FBI', '）', '人員', '逮捕', '這名', '男子', '被控', '企圖供', '應物', '資給', '伊斯', '蘭國', '（', 'IS', '）', '司法部', '聲明', '說', 'FBI', '瓦解', '勒', '奇曼', '（', 'Emanuel', ' ', 'Lutchman', '）', '企圖', '在', '除夕夜', '殺害', '平民', '的', '計畫', '但', '仍', '憂慮', '海外', '的', '人', '利用', '網路', '煽動', '美國境', '內', '的', '人', '從', '事', '暴力', '活動', '2016', '元旦', '健走', '上午', '在', '台北', '花博公園', '登場', '吸引', '超過', '兩萬人', '參加', '活動', '發起', '人紀', '政呼籲', '國人', '重視', '健康', '抗癌', '田徑', '名將', '古', '金水', '2014', '年底', '診斷', '出', '癌症', '他', '帶', '著兒', '女', '出席', '健走', '活動', '並感謝', '外界', '支持', '跟', '鼓勵', '頂級', '保養', '品牌', '肌膚', '之', '鑰', '發表', '全新', '光采', '保養', '系列', '強調', '光采', '是', '一切', '美白', '保濕', '抗老', '等', '美', '肌護膚', '的', '最高', '境界', '此次', '並以', '在', '泰國', '秘境', '獨家育種', '出', '全新', '的', '白金', '絲繭', '為主', '成分', '訴求', '可', '隔絕', '紫外', '線', '等', '外部', '環境', '對', '肌膚', '造成', '的', '傷害', '所謂', '的', '「', '白金', '絲繭', '」', '是', '由', '奢華', '的', '黃', '金繭', '與', '日本', '高品質', '的', '純白繭', '結合', '而成', '除', '不', '使用', '農藥', '獨家育種', '外', '並採', '獨家', '技術', '讓', '所有', '來', '自蠶絲', '的', '營養', '成分', '可一絲', '不漏', '的', '加入', '全新', '光采', '保養', '系列', '品項', '中', '此外', '這次', '肌膚', '之', '鑰', '也', '提出', '全新', '的', '「', '新肌膚', '腦細胞', '理論', '」', '發現', '到', '肌膚', '不僅會', '思考', '感受', '壓力', '選擇', '喜好', '成分', '外', '肌膚', '還擁', '有', '記憶', '能力', '會', '因過', '去', '所', '受', '的', '情緒', '、', '壓力', '、', '紫外', '線', '傷害', '等', '形成', '記憶', '而', '新', '肌膚', '腦細胞', '理論', '指的則', '是', '要', '讓', '這些', '負面', '的', '壓力', '不成', '為', '未來', '的', '記憶', '不', '讓', '負面', '壓力', '情緒', '影響', '未來', '的', '膚況', '因此', '除了', '「', '白金', '絲繭', '」', '這奢華', '成分', '外', '即將', '於', '月', '20', '日', '上市', '的', '全新', '光采', '保養', '系列', '裡頭還', '添加', '有', '茶', '氨酸', '、', '白木耳', '以及']\n"
     ]
    }
   ],
   "source": [
    "#for i in range(len(ans_1)):\n",
    "ans_1.remove(\"，\")\n",
    "ans_1.remove(\"。\")\n",
    "ans_1.remove(\",\")\n",
    "ans_1.remove(\"(\")\n",
    "ans_1.remove(\")\")\n",
    "ans_1.remove(\"1\")\n",
    "ans_1.remove(\"2\")\n",
    "ans_1.remove(\"3\")\n",
    "ans_1.remove(\"4\")\n",
    "ans_1.remove(\"5\")\n",
    "ans_1.remove(\"6\")\n",
    "ans_1.remove(\"7\")\n",
    "ans_1.remove(\"8\")\n",
    "ans_1.remove(\"9\")\n",
    "ans_1.remove(\"10\")\n",
    "ans_1.remove(\"0\")\n",
    "ans_1.remove(\"「\")\n",
    "ans_1.remove(\"」\")\n",
    "ans_1.remove(\"：\")\n",
    "#ans_1.remove(\":\")\n",
    "print(ans_1[1:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3625640\n"
     ]
    }
   ],
   "source": [
    "import re \n",
    "aws = []\n",
    "#aws = re.sub(r'[^\\w]','',ans_1)\n",
    "for i in range(len(ans_1)):\n",
    "    aws.append(re.sub(r'[A-Za-z0-9]','',ans_1[i]))\n",
    "#aws = re.sub(r'[A-Za-z0-9]','',ans_1)\n",
    "print(len(aws))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3625659\n",
      "141292\n"
     ]
    }
   ],
   "source": [
    "print(len(ans_1))\n",
    "print(len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1292, 984, 1648, 258, 2320, 266, 16, 1730, 502, 902, 1136, 628, 5570, 158, 4020, 1542, 3284, 2096, 2008, 1238, 6594, 1154, 608, 1656, 13854, 1928, 1442, 670, 658, 12, 200, 632, 842, 140, 7996, 2548, 2160, 626, 130, 8, 8, 30, 1768, 6, 3436, 1100, 1960, 152, 58, 1488, 2138, 612, 10, 504, 418, 478, 280, 316, 410, 740, 204, 944, 852, 2346, 2118, 1682, 54, 10, 864, 1218, 420, 2704, 422, 1210, 3424, 676, 258, 1108, 804, 310, 1204, 1524, 562, 2908, 3332, 690, 390, 118, 844, 2176, 382, 244, 198, 1896, 78, 1886, 200, 778, 482, 76, 76, 1180, 2572, 1274, 1186, 214, 464, 840, 13524, 224, 1100, 638, 4380, 4204, 310, 800, 286, 11202, 410, 54, 998, 198, 30, 254, 654, 1510, 3206, 700, 1318, 172, 24, 9372, 242, 34, 882, 7030, 24, 622, 1146, 26, 758, 1710, 362, 3410, 238, 618, 690, 872, 594, 494, 90, 24, 136, 1542, 498, 734, 2934, 1628, 748, 1748, 524, 132, 62, 246, 514, 240, 446, 342, 4127, 814, 178, 5052, 1822, 148, 1334, 66, 72, 710, 158, 172, 810, 14, 224, 3474, 148, 526, 6564, 1196, 3255, 166, 1550, 836, 50, 682, 454, 2160, 1152, 278, 134, 1272, 1120, 354, 418, 2754, 300, 490, 6, 300, 1824, 140, 524, 22, 28, 28636, 210, 340, 1176, 524, 248, 810, 1260, 914, 5198, 468, 420, 328, 226, 360, 2134, 12, 10, 602, 358, 890, 218, 3034, 32, 732, 668, 158, 10, 234, 302, 240, 24, 1778, 7143, 1176, 1876, 182, 328, 850, 822, 264, 2406, 50, 152, 106, 1046, 874, 12, 2900, 646, 1494, 1042, 670, 16, 6, 94, 12, 768, 1002, 260, 664, 762, 34, 4562, 1230, 4658, 306, 208, 122, 728, 256, 1228, 410, 28636, 232, 228, 1740, 1318, 582, 1314, 102, 1500, 3526, 1116, 52, 24, 120, 80, 162, 2784, 30, 3370, 210, 5856, 10, 1344, 2644, 1470, 352, 248, 2570, 16120, 1030, 2262, 268, 42, 8902, 790, 1068, 962, 664, 2020, 1510, 1830, 834, 2808, 5391, 3006, 52, 404, 244, 7114, 276, 2744, 170, 450, 1532, 870, 286, 1678, 1062, 1974, 626, 120, 318, 254, 502, 514, 118, 1640, 1130, 276, 1348, 1728, 536, 7088, 492, 1644, 390, 124, 4798, 74, 1160, 3916, 3114, 1384, 474, 2060, 120, 682, 50, 1774, 2802, 600, 1642, 78, 260, 398, 382, 2048, 522, 256, 544, 3120, 2506, 8, 16570, 101086, 6, 6650, 564, 2646, 20, 788, 2814, 104, 960, 1578, 2274, 630, 1012, 136, 24, 1110, 1050, 3896, 372, 118, 70, 100, 450, 1230, 3984, 5987, 6, 1400, 400, 22, 1690, 1788, 48, 62, 238, 510, 1942, 7166, 858, 1264, 924, 26, 920, 36, 18300, 74, 670, 60, 1894, 582, 112, 56, 5512, 532, 470, 220, 1150, 1044, 1634, 6, 10, 424, 266, 1132, 2246, 46, 534, 3777, 774, 556, 311773, 1128, 386, 1868, 6020, 12, 9782, 762, 1056, 506, 950, 44, 116, 130, 2276, 1542, 42, 256, 10542, 1564, 26, 1510, 54, 152, 636, 1470, 1804, 114, 1294, 1906, 170, 1242, 44, 1318, 622, 546, 24, 36, 1302, 30500, 24, 3038, 6072, 332, 460, 386, 3070, 2022, 2530, 314, 1290, 5420, 640, 31374, 894, 1642, 202, 1980, 608, 194, 4642, 304, 4268, 442, 966, 146, 554, 1202, 1124, 736, 1478, 118, 6994, 6, 120, 1268, 872, 512, 8250, 256, 1046, 476, 4160, 2728, 820, 100, 2564, 6, 100, 36, 8, 688, 1024, 1360, 378, 256, 2052, 4308, 54, 1680, 66, 670, 1972, 1186, 684, 852, 910, 2410, 2320, 184, 782, 9682, 444, 1478, 1176, 1992, 2162, 4706, 10274, 2968, 1038, 278, 28, 624, 3142, 908, 718, 2300, 238, 1240, 844, 808, 2234, 26, 412, 466, 3448, 1070, 28, 1074, 676, 2044, 328, 432, 810, 1100, 6, 786, 1394, 17478, 162, 4618, 1500, 76, 4592, 2124, 14118, 986, 8, 20832, 12, 1094, 5856, 1608, 1444, 106, 1216, 16548, 230, 2106, 734, 1160, 1816, 404, 46, 3973, 42, 1446, 1702, 1138, 62, 556, 14876, 676, 256, 140, 18, 1014, 80, 50, 6778, 60, 2080, 1710, 30, 8, 20, 1634, 108, 11018, 1276, 3178, 1146, 1552, 10, 1276, 104, 1810, 48954, 2720, 718, 2930, 1780, 7600, 10, 32, 952, 18, 704, 426, 1520, 50, 2330, 276, 442, 422, 770, 2572, 456, 8884, 548, 2758, 8690, 918, 2018, 1014, 42, 1038, 120, 62, 214, 26, 792, 2958, 372, 142, 662, 1570, 4816, 6862, 5058, 1096, 384, 1046, 534, 1498, 454, 688, 198, 1208, 1178, 1766, 482, 1022, 678, 12, 410, 186, 2724, 1766, 634, 1244, 62, 1458, 38, 4260, 564, 1592, 654, 938, 702, 536, 780, 38, 1294, 306, 1282, 182, 1464, 156, 30, 60, 1340, 232, 232, 360, 72, 280, 136, 1542, 744, 1726, 442, 32, 16, 1282, 3423, 3744, 9320, 1118, 1018]\n"
     ]
    }
   ],
   "source": [
    "a = list(set(ans_1))\n",
    "#print(a[1:500])\n",
    "\n",
    "count_1 = []\n",
    "for i in range(len(a)):\n",
    "    num = 0 \n",
    "    for k in range(len(ans_1)):\n",
    "        if a[i] == ans_1[k]:\n",
    "            num += 1 \n",
    "        if k ==10000 and num < 3:\n",
    "            count_1 += [0]\n",
    "            break\n",
    "    if num >= 3:\n",
    "        count_1 += [num]\n",
    "        \n",
    "    \n",
    "\n",
    "print(count_1[1:5000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['職業賽', '職落', '台灣民眾過', '及紅利點', '前當', '射擊島', '撐過', '624.97', '0.4%', '及大陸', '林知', '搬演', '修養', '輕到', '指揮', '過該', '壺組', '海持續', '江蕙', '給全', '裝盛著', '改還', '元太召開', '人輕', '中決定', '晶贊', '同日', '廚具', '實施者', '拆紅', '客運闢', '已明確', '義隆電', '起將合', '智權', '塞勒', '年市', '大陸現', '谷車', '見樂觀', '237%', '投資信', '雖未明', '著唱國歌', '賓衛生', '核准制', '獅和', '商當前', '實用', '閣', '試將', '正己', '劇錄', '廚神', '巫統', '環保局', '連來', '產過程', '電價價', '26.92', '俯視', '賀陳弘', '賠本', '以掛', '應比', '人候', '六個', '戰戰兢兢地', '金財務長', '太好了', '財產來源', '明堂', '資金無法', 'Make', '點邁進', '效抗體', '473', '於極', '將提燈', '還約詢', 'eMMC', '擬確', '數十人', '正規畫', '非威航', '超殺', '連虧', '飯館', 'm', '你講', '渾身', '各國船', '還湧現', '6224', 'N9300', '廣州粵海關', '將發射', '商業者', '對朝鮮', '退還']\n"
     ]
    }
   ],
   "source": [
    "print(a[0:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "773\n"
     ]
    }
   ],
   "source": [
    "print(count_1[6000:6020])\n",
    "print(len(count_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(count_1[5000:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "652\n",
      "362516\n"
     ]
    }
   ],
   "source": [
    "##信用卡\n",
    "from nltk.classify.megam import numpy\n",
    "array=numpy.array(index_list[1])\n",
    "#print(collections[array])\n",
    "a_1 = df.iloc[array,[3]]\n",
    "a_2 = df.iloc[array,[4]]\n",
    "#print(a_2)\n",
    "rr = a_2.iloc[3,0]\n",
    "print(len(index_list[1]))\n",
    "#print(type(str(a_1[5:6])))\n",
    "words = []\n",
    "words_2 = []\n",
    "for i in range(len(index_list[1])):\n",
    "#words = jieba.lcut(a , cut_all=False)\n",
    "    #words = jieba.lcut(str(a_2.iloc[i,0]) , cut_all=False)\n",
    "    #words_2 = jieba.lcut(str(a_1.iloc[i,0]) , cut_all=False)\n",
    "    words +=(jieba.lcut(str(a_2.iloc[i,0]) , cut_all=False))\n",
    "    words_2 +=(jieba.lcut(str(a_2.iloc[i,0]) , cut_all=False))\n",
    "ans_2 = words + words_2\n",
    "#for word in ans_1:\n",
    " #   print(word)\n",
    "print(len(ans_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1941\n",
      "1000826\n"
     ]
    }
   ],
   "source": [
    "##匯率\n",
    "from nltk.classify.megam import numpy\n",
    "array=numpy.array(index_list[2])\n",
    "#print(collections[array])\n",
    "a_1 = df.iloc[array,[3]]\n",
    "a_2 = df.iloc[array,[4]]\n",
    "#print(a_2)\n",
    "rr = a_2.iloc[3,0]\n",
    "print(len(index_list[2]))\n",
    "#print(type(str(a_1[5:6])))\n",
    "words = []\n",
    "words_2 = []\n",
    "for i in range(len(index_list[2])):\n",
    "#words = jieba.lcut(a , cut_all=False)\n",
    "    #words = jieba.lcut(str(a_2.iloc[i,0]) , cut_all=False)\n",
    "    #words_2 = jieba.lcut(str(a_1.iloc[i,0]) , cut_all=False)\n",
    "    words +=(jieba.lcut(str(a_2.iloc[i,0]) , cut_all=False))\n",
    "    words_2 +=(jieba.lcut(str(a_2.iloc[i,0]) , cut_all=False))\n",
    "ans_3 = words + words_2\n",
    "#for word in ans_1:\n",
    " #   print(word)\n",
    "print(len(ans_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1736\n",
      "942462\n"
     ]
    }
   ],
   "source": [
    "##台積電\n",
    "from nltk.classify.megam import numpy\n",
    "array=numpy.array(index_list[3])\n",
    "#print(collections[array])\n",
    "a_1 = df.iloc[array,[3]]\n",
    "a_2 = df.iloc[array,[4]]\n",
    "#print(a_2)\n",
    "rr = a_2.iloc[3,0]\n",
    "print(len(index_list[3]))\n",
    "#print(type(str(a_1[5:6])))\n",
    "words = []\n",
    "words_2 = []\n",
    "for i in range(len(index_list[3])):\n",
    "#words = jieba.lcut(a , cut_all=False)\n",
    "    #words = jieba.lcut(str(a_2.iloc[i,0]) , cut_all=False)\n",
    "    #words_2 = jieba.lcut(str(a_1.iloc[i,0]) , cut_all=False)\n",
    "    words +=(jieba.lcut(str(a_2.iloc[i,0]) , cut_all=False))\n",
    "    words_2 +=(jieba.lcut(str(a_2.iloc[i,0]) , cut_all=False))\n",
    "ans_4 = words + words_2\n",
    "#for word in ans_1:\n",
    " #   print(word)\n",
    "print(len(ans_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27118\n",
      "14596388\n"
     ]
    }
   ],
   "source": [
    "##台灣\n",
    "from nltk.classify.megam import numpy\n",
    "array=numpy.array(index_list[4])\n",
    "#print(collections[array])\n",
    "a_1 = df.iloc[array,[3]]\n",
    "a_2 = df.iloc[array,[4]]\n",
    "#print(a_2)\n",
    "rr = a_2.iloc[3,0]\n",
    "print(len(index_list[4]))\n",
    "#print(type(str(a_1[5:6])))\n",
    "words = []\n",
    "words_2 = []\n",
    "for i in range(len(index_list[4])):\n",
    "#words = jieba.lcut(a , cut_all=False)\n",
    "    #words = jieba.lcut(str(a_2.iloc[i,0]) , cut_all=False)\n",
    "    #words_2 = jieba.lcut(str(a_1.iloc[i,0]) , cut_all=False)\n",
    "    words +=(jieba.lcut(str(a_2.iloc[i,0]) , cut_all=False))\n",
    "    words_2 +=(jieba.lcut(str(a_2.iloc[i,0]) , cut_all=False))\n",
    "ans_5 = words + words_2\n",
    "#for word in ans_1:\n",
    " #   print(word)\n",
    "print(len(ans_5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8232\n",
      "4419876\n"
     ]
    }
   ],
   "source": [
    "##日本\n",
    "from nltk.classify.megam import numpy\n",
    "array=numpy.array(index_list[5])\n",
    "#print(collections[array])\n",
    "a_1 = df.iloc[array,[3]]\n",
    "a_2 = df.iloc[array,[4]]\n",
    "#print(a_2)\n",
    "rr = a_2.iloc[3,0]\n",
    "print(len(index_list[5]))\n",
    "#print(type(str(a_1[5:6])))\n",
    "words = []\n",
    "words_2 = []\n",
    "for i in range(len(index_list[5])):\n",
    "#words = jieba.lcut(a , cut_all=False)\n",
    "    #words = jieba.lcut(str(a_2.iloc[i,0]) , cut_all=False)\n",
    "    #words_2 = jieba.lcut(str(a_1.iloc[i,0]) , cut_all=False)\n",
    "    words +=(jieba.lcut(str(a_2.iloc[i,0]) , cut_all=False))\n",
    "    words_2 +=(jieba.lcut(str(a_2.iloc[i,0]) , cut_all=False))\n",
    "ans_6 = words + words_2\n",
    "#for word in ans_1:\n",
    " #   print(word)\n",
    "print(len(ans_6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "_RTS2 = {}\n",
    "def preprocess(sent,n_gram,stopword):\n",
    "    sent = re.sub(r'[^\\w]','',sent)\n",
    "    sent = re.sub(r'[A-Za-z0-9]',\"\",sent)\n",
    "    \n",
    "    return_list = []\n",
    "    s = sent[0]\n",
    "    for i in range(len(sent)):\n",
    "        w = sent[i]\n",
    "        if w not in stopword:\n",
    "            s += w\n",
    "    return s\n",
    "\n",
    "token = \"銀行\"\n",
    "for index, val in collections.iterrows():\n",
    "    if token in val[\"標題\"]+val[\"內容\"]:\n",
    "        _RTS2[index] = preprocess(val[\"標題\"]+val[\"內容\"],2,stopword)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "words =[]\n",
    "for key,value in _RTS2.items():#当两个参数时\n",
    "    #print(key ,':' , value)\n",
    "    words += (jieba.lcut(value, cut_all=False) )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,value in _RTS2.items():#当两个参数时\n",
    "    print(value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['國國', '銀陸', '分行', '爆逾放國', '銀陸', '分行', '爆逾放', '新增', '台銀家', '金會', '昨日', '公布', '新國', '銀營運', '概況', '陸', '分行', '接兩月', '暴增', '逾', '放出', '現逾放', '銀', '行家', '數', '增加', '三家', '台資', '銀登陸', '顯見陸', '授信', '風險', '升高', '金會', '銀行局', '副', '局長', '邱淑貞', '表示', '台銀', '踩', '逾', '放土', '銀', '家事', '工具', '機', '台商', '公司', '目前', '知道', '三家', '台資', '銀行', '貸款', '家', '台商', '台銀土', '銀外家', '富邦', '金陸子', '行華銀行', '國銀陸', '分行', '逾放', '家家', '爆', '邱淑貞', '表示', '銀行', '國外', '開拓', '市場', '機會', '風險', '銀行', '注意', '風控', '逾', '放出', '更', '進步', '加強', '風險', '控金會', '昨天', '發布國', '銀行營', '概況', '年', '月底', '止國', '銀陸', '分行', '逾', '放出', '現', '增加', '情況', '年', '逾', '放合庫', '外年', '月', '新增', '土銀外', '跑', '出台', '銀逾放', '金額', '萬元國', '銀登陸', '營運合', '庫陸', '分行', '首度', '出現', '逾', '放年', '月', '國泰世華', '銀行陸', '分行', '踩', '逾', '放', '月', '月', '接', '新增', '土銀台', '銀', '兩家', '年', '首度', '續', '三家', '國銀陸', '分行', '踩', '逾', '放', '中國', '泰世華銀行', '掉', '陸', '分行', '目前', '逾放', '銀行局', '表示', '台銀土', '銀筆', '放款', '象', '貸款', '家事', '工具', '機', '台商', '公司', '營佳出', '錢', '變成', '逾', '放', '根金會', '新資料', '月底', '台銀陸', '分行', '逾放金額', '萬元', '占', '放款', '率台', '銀陸', '分行', '次出', '現逾放', '銀行業', '表示', '陸濟', '成長', '放緩', '授信', '風險', '升高', '少銀行', '減少', '陸區', '放款', '國銀陸', '分行', '接', '踩', '逾', '放國', '銀', '授信', '更', '趨謹慎國', '銀陸', '分行', '逾放', '增加', '金會強', '調接', '採取', '項', '措施', '求銀行', '加強', '控陸區', '風險陸', '曝險', '控加', '強金', '檢外', '國銀', '獲利', '方面', '年前', '月', '獲利', '億', '元年', '衰退', '中陸', '分行', '減幅', '衰退', '國際', '金融', '業務', '分行', '衰退', '台台', '銀', '審慎原', '轉銷', '呆', '帳台灣', '銀行陸', '分行', '月', '新增', '筆萬元', '逾期', '放款', '逾期', '放款', '率', '提升', '解發生', '逾', '放家', '台資', '工具', '機業', '工廠', '設海台', '銀', '昨日', '低調', '回應筆', '放款', '出現', '問題', '基審慎', '原台', '銀陸', '監理機', '關求', '轉銷', '呆', '帳陸', '曝險', '快速', '攀升', '濟滑', '引發', '銀行', '放款', '恐出', '現逾放', '風險', '年', '持續', '立法院', '關心', '話題', '年', '半年', '中國', '旭光', '高新', '企業', '倒帳', '九家', '台資', '銀行共出', '億', '美元', '年', '半年', '爆出', '福建', '索力', '倒帳', '包括', '六家', '國銀', '金融', '機構', '共款', '萬', '美元', '年', '七家', '國銀行', '辦理', '聯貸', '陸漢集', '團案', '受', '矚目解', '目前', '金會', '緊', '盯', '國銀陸', '授信', '情況', '專案', '指示', '存保', '公司', '針銀行陸', '曝險', '情況', '加強', '監控', '狀況', '立通', '報例', '中國核', '工業', '集團', '中國', '兵器', '工業', '集團家', '企業', '存保', '列入', '示警', '名單', '中', '馬', '馬', '元旦', '文告', '全文', '八年', '興革', '臺', '灣', '升格', '馬', '英九總統', '早', '發表次', '元旦', '文告', '八年', '興革', '臺', '灣', '升格', '主題', '提出', '未', '三', '提醒', '詞', '全文', '天中華民國', '年', '開國紀念', '日', '八年', '年', '元旦', '會家', '回顧展', '天選出', '中華民國', '正副', '總統', '天次', '元旦', '詞想利', '機會', '全體', '國表達', '心誠摯', '感謝', '感謝', '臺', '灣民', '兩次', '選', '中信', '託', '付', '機會位', '拚', '創造', '許前', '未', '豐碩', '成果', '說', '深感', '動接', '想位', '談談', '三', '關鍵', '成果', '臺', '灣未', '三誠懇', '提醒', '希', '分享', '成果', '時', '思考', '面挑戰', '壹', '關鍵', '成果', '外交', '躍進', '友善', '國際', '七年', '努力', '推動', '活路', '外交', '扮演', '平締造', '道', '援助', '角色', '取豐碩', '成果', '贏國際', '社會', '尊敬', '舉例', '說', '美國日', '歐盟', '東協紐', '澳國', '安全', '貿', '文教', '方面', '關', '係', '三四十年', '狀態', '美國國', '軍售', '超億', '美元', '前', '兩', '總統', '時期', '增加', '非常', '合作', '更', '密切', '七年', '日', '簽訂', '協議', '占', '年', '雙方', '簽項', '協議', '超許']\n"
     ]
    }
   ],
   "source": [
    "print(words[0:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = [] \n",
    "for key in _RTS2.keys(): #每一篇文章\n",
    "    for w in _RTS2[key]: #每一個字\n",
    "        df = sum([w in _RTS2[k] for k in _RTS2.keys()])\n",
    "        df_list.append((w,df))\n",
    "df_list = list(set(df_list)) #去除重複\n",
    "df_list = sorted(df_list, key = lambda x:x[1], reverse = True) #由大排到小\n",
    "df_list\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
