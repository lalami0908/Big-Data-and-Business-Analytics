{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'p_type', 's_name', 's_area_name', 'post_time', 'title', 'author',\n",
      "       'content', 'page_url'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import jieba\n",
    "import jieba.analyse\n",
    "import re\n",
    "import pandas as pd\n",
    "import urllib.parse as ur\n",
    "import os \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#os.getcwd()\n",
    "df = pd.DataFrame(pd.read_csv('news.csv')) #讀取新聞文章並以變數df儲存\n",
    "print(df.columns) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--------------------------------\n",
    "# 存停用詞, 分詞, 過濾後分詞的list\n",
    "#--------------------------------\n",
    "stopWords=[]\n",
    "#--------------------------------\n",
    "# 讀入停用詞檔\n",
    "#--------------------------------\n",
    "with open('stopword.txt', 'r', encoding='UTF-8') as file:\n",
    "    for data in file.readlines():\n",
    "        data = data.strip()\n",
    "        stopWords.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298\n",
      "603\n"
     ]
    }
   ],
   "source": [
    "#找包含關鍵字文章\n",
    "mtk_up = df[\"content\"].str.contains('聯發科')  #為一布林值list，儲存(df)新聞內文(content欄位)中是否含有「聯發科」\n",
    "#b= df[df[\"content\"].isin['聯發科',\"上漲\"]]\n",
    "count_down = 0 #計算總共有幾篇文章被標記為跌\n",
    "index_down = [] #儲存被標記為跌的文章在df中的index\n",
    "count_up = 0 #計算總共有幾篇文章被標記為漲\n",
    "index_up = [] #儲存被標記為漲的文章在df中的index\n",
    "for i in range(len(mtk_up)):\n",
    "    # 文章包含「上漲」或「漲」字詞但不包含「下跌」或「跌」字詞才可以被標記為漲\n",
    "    # 文章包含「下跌」或「跌」字詞但不包含「上漲」或「漲」字詞才可以被標記為跌\n",
    "    if (mtk_up[i] == True) and((df['content'][i].find('下跌')!=-1) or (df['content'][i].find('跌')!=-1))and ((df['content'][i].find('上漲')==-1) and (df['content'][i].find('漲')==-1)):\n",
    "         count_down += 1 \n",
    "         index_down += [i]\n",
    "    elif (mtk_up[i] == True) and((df['content'][i].find('上漲')!=-1) or (df['content'][i].find('漲')!=-1))and((df['content'][i].find('下跌')==-1) and (df['content'][i].find('跌')==-1)):\n",
    "         count_up += 1\n",
    "         index_up += [i]\n",
    "print(count_down) \n",
    "print(count_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text_all = [] #存取jieba切詞後的所有新聞內容，長相會是[\"財經 新聞 內容 報導......\", \"聯發科 股票 本月 預估 ......\",......]\n",
    "label_all = [] #存取各篇新聞的漲跌標記\n",
    "\n",
    "sent_down = [] #存取jieba切詞後的所有下跌新聞內容，長相會是[\"財經 新聞 內容 報導......\", \"聯發科 股票 本月 預估 ......\",......]\n",
    "for i in index_down: \n",
    "    text_down = df.iloc[i].content #提取下跌文章的內文並暫時以text_down變數儲存\n",
    "    text_down = re.sub(r'[^\\w]','',text_down) #將無意義的符號刪掉\n",
    "    text_down = re.sub(r'[A-Za-z0-9]','',text_down) #將數字或是英文刪掉\n",
    "    temp_down = '' #暫時儲存以空白隔開的字詞string\n",
    "    segments_down=[] #儲存所有jieba切割出的字詞\n",
    "    remainderWords_down=[] #儲存刪除stopWord之後的字詞list\n",
    "    segments_down = jieba.cut(text_down, cut_all=False) #以jieba切割text_down字串並將所有切割出的字詞儲存至segments_down\n",
    "    remainderWords_down = list(filter(lambda a: a not in stopWords and a != '\\n', segments_down)) #刪除segments_down中是stopWords字詞\n",
    "    \n",
    "    cnt = 0 \n",
    "    for k in remainderWords_down: #這個迴圈的用意是要將remainderWords_down中的字詞list以一條string形式儲存，每個字詞以空白隔開，之後才能讀入KNN套件\n",
    "        if (cnt == 0) or (cnt == len(remainderWords_down)): \n",
    "            temp_down += (k)\n",
    "        else:\n",
    "            temp_down += ' '\n",
    "            temp_down += k\n",
    "        cnt += 1\n",
    "    sent_down.append(temp_down) #將temp_down append到sent_down中\n",
    "    \n",
    "sent_up = [] #存取jieba切詞後的所有上漲新聞內容，長相會是[\"財經 新聞 內容 報導......\", \"聯發科 股票 本月 預估 ......\",......]\n",
    "for i in index_up:\n",
    "    text_up = df.iloc[i].content\n",
    "    text_up = re.sub(r'[^\\w]','',text_up)\n",
    "    text_up = re.sub(r'[A-Za-z0-9]','',text_up)\n",
    "    temp_up = ''\n",
    "    segments_up=[]\n",
    "    remainderWords_up=[]\n",
    "    segments_up = jieba.cut(text_up, cut_all=False)\n",
    "    remainderWords_up = list(filter(lambda a: a not in stopWords and a != '\\n', segments_up))\n",
    "    cnt = 0\n",
    "    for k in remainderWords_up:\n",
    "        if (cnt == 0) or (cnt == len(remainderWords_up)):\n",
    "            temp_up += (k)\n",
    "        else:\n",
    "            temp_up += ' '\n",
    "            temp_up += k\n",
    "        cnt += 1\n",
    "    sent_up.append(temp_up)\n",
    "\n",
    "for i in range(len(sent_down)):\n",
    "    text_all.append(sent_down[i]) #將sent_down所有以字詞組成的文章存到text_all中\n",
    "    label_all.append(int(0)) #將label_all中同一index的儲存格存取\"0\"，代表下跌\n",
    "    \n",
    "for i in range(len(sent_up)):\n",
    "    text_all.append(sent_up[i]) #將sent_up所有以字詞組成的文章存到text_all中\n",
    "    label_all.append(int(1)) #將label_all中同一index的儲存格存取\"1\"，代表上漲\n",
    "    \n",
    "#label_all的長相會是前面全都是0後面全都是1，[0,0,0,0.....,1,1,1,]，剛好配合下跌與上漲文章在text_all中的順序，這樣讀入KNN套件時才能成功"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(901, 40661)\n",
      "  (0, 40269)\t2\n",
      "  (0, 33242)\t3\n",
      "  (0, 32448)\t1\n",
      "  (0, 19062)\t1\n",
      "  (0, 25468)\t1\n",
      "  (0, 10750)\t1\n",
      "  (0, 26605)\t3\n",
      "  (0, 24895)\t6\n",
      "  (0, 26173)\t2\n",
      "  (0, 9827)\t1\n",
      "  (0, 32201)\t2\n",
      "  (0, 24876)\t2\n",
      "  (0, 34422)\t1\n",
      "  (0, 18496)\t2\n",
      "  (0, 35222)\t2\n",
      "  (0, 36373)\t1\n",
      "  (0, 10751)\t1\n",
      "  (0, 2842)\t1\n",
      "  (0, 37114)\t1\n",
      "  (0, 32697)\t1\n",
      "  (0, 2247)\t1\n",
      "  (0, 24160)\t1\n",
      "  (0, 15463)\t6\n",
      "  (0, 6472)\t2\n",
      "  (0, 20638)\t1\n",
      "  :\t:\n",
      "  (900, 11979)\t1\n",
      "  (900, 3996)\t1\n",
      "  (900, 39014)\t1\n",
      "  (900, 10253)\t1\n",
      "  (900, 12511)\t1\n",
      "  (900, 35402)\t1\n",
      "  (900, 40626)\t1\n",
      "  (900, 28769)\t1\n",
      "  (900, 24082)\t1\n",
      "  (900, 32937)\t1\n",
      "  (900, 540)\t1\n",
      "  (900, 1200)\t1\n",
      "  (900, 14533)\t1\n",
      "  (900, 1277)\t1\n",
      "  (900, 8293)\t1\n",
      "  (900, 19202)\t1\n",
      "  (900, 28741)\t1\n",
      "  (900, 10053)\t1\n",
      "  (900, 13298)\t1\n",
      "  (900, 31366)\t1\n",
      "  (900, 13438)\t1\n",
      "  (900, 32271)\t1\n",
      "  (900, 16574)\t1\n",
      "  (900, 6294)\t1\n",
      "  (900, 35906)\t1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer #利用套件抓取所有文章中的關鍵字\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "cv = CountVectorizer()\n",
    "cv_fit=cv.fit_transform(text_all)\n",
    "print(cv_fit.toarray()) #這個是每個文章的對上所有關鍵字tf list\n",
    "print(cv_fit.toarray().shape) #(文章數, 關鍵字數量)\n",
    "print(cv_fit) #(文章對上所有關鍵字的tf細項 ex:(第X篇文章 , 第Y個關鍵字) tf)\n",
    "# print(cv.get_feature_names())\n",
    "x = cv_fit \n",
    "y = label_all #將所有文章的漲跌標記以y變數儲存\n",
    "\n",
    "#利用train_test_split將所有文章隨意分割成training set和testing set\n",
    "#X_train, X_test, y_train, y_test = 文章的training data,文章的testing data, 漲跌標記的training data,漲跌標記的testing dat \n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=101) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1\n",
      "[[ 32  34]\n",
      " [ 11 104]]\n",
      "Accuracy= 0.7513812154696132\n",
      "R= 0.9043478260869565\n",
      "P= 0.7536231884057971\n",
      "F1= 0.8221343873517787\n",
      "---------------------------------------------------------------------------------\n",
      "k= 3\n",
      "[[ 27  39]\n",
      " [ 10 105]]\n",
      "Accuracy= 0.7292817679558011\n",
      "R= 0.9130434782608695\n",
      "P= 0.7291666666666666\n",
      "F1= 0.8108108108108107\n",
      "---------------------------------------------------------------------------------\n",
      "k= 5\n",
      "[[ 25  41]\n",
      " [  5 110]]\n",
      "Accuracy= 0.7458563535911602\n",
      "R= 0.9565217391304348\n",
      "P= 0.7284768211920529\n",
      "F1= 0.8270676691729324\n",
      "---------------------------------------------------------------------------------\n",
      "k= 7\n",
      "[[ 20  46]\n",
      " [  5 110]]\n",
      "Accuracy= 0.7182320441988951\n",
      "R= 0.9565217391304348\n",
      "P= 0.7051282051282052\n",
      "F1= 0.8118081180811809\n",
      "---------------------------------------------------------------------------------\n",
      "k= 9\n",
      "[[ 22  44]\n",
      " [  5 110]]\n",
      "Accuracy= 0.7292817679558011\n",
      "R= 0.9565217391304348\n",
      "P= 0.7142857142857143\n",
      "F1= 0.8178438661710038\n",
      "---------------------------------------------------------------------------------\n",
      "k= 11\n",
      "[[ 24  42]\n",
      " [  3 112]]\n",
      "Accuracy= 0.7513812154696132\n",
      "R= 0.9739130434782609\n",
      "P= 0.7272727272727273\n",
      "F1= 0.8327137546468402\n",
      "---------------------------------------------------------------------------------\n",
      "k= 13\n",
      "[[ 20  46]\n",
      " [  3 112]]\n",
      "Accuracy= 0.7292817679558011\n",
      "R= 0.9739130434782609\n",
      "P= 0.7088607594936709\n",
      "F1= 0.8205128205128206\n",
      "---------------------------------------------------------------------------------\n",
      "k= 15\n",
      "[[ 22  44]\n",
      " [  1 114]]\n",
      "Accuracy= 0.7513812154696132\n",
      "R= 0.991304347826087\n",
      "P= 0.7215189873417721\n",
      "F1= 0.8351648351648353\n",
      "---------------------------------------------------------------------------------\n",
      "k= 17\n",
      "[[ 22  44]\n",
      " [  3 112]]\n",
      "Accuracy= 0.7403314917127072\n",
      "R= 0.9739130434782609\n",
      "P= 0.717948717948718\n",
      "F1= 0.8265682656826568\n",
      "---------------------------------------------------------------------------------\n",
      "k= 19\n",
      "[[ 25  41]\n",
      " [  2 113]]\n",
      "Accuracy= 0.7624309392265194\n",
      "R= 0.9826086956521739\n",
      "P= 0.7337662337662337\n",
      "F1= 0.8401486988847584\n",
      "---------------------------------------------------------------------------------\n",
      "k= 21\n",
      "[[ 24  42]\n",
      " [  3 112]]\n",
      "Accuracy= 0.7513812154696132\n",
      "R= 0.9739130434782609\n",
      "P= 0.7272727272727273\n",
      "F1= 0.8327137546468402\n",
      "---------------------------------------------------------------------------------\n",
      "k= 23\n",
      "[[ 23  43]\n",
      " [  3 112]]\n",
      "Accuracy= 0.7458563535911602\n",
      "R= 0.9739130434782609\n",
      "P= 0.7225806451612903\n",
      "F1= 0.8296296296296296\n",
      "---------------------------------------------------------------------------------\n",
      "k= 25\n",
      "[[ 25  41]\n",
      " [  3 112]]\n",
      "Accuracy= 0.7569060773480663\n",
      "R= 0.9739130434782609\n",
      "P= 0.7320261437908496\n",
      "F1= 0.835820895522388\n",
      "---------------------------------------------------------------------------------\n",
      "k= 27\n",
      "[[ 26  40]\n",
      " [  3 112]]\n",
      "Accuracy= 0.7624309392265194\n",
      "R= 0.9739130434782609\n",
      "P= 0.7368421052631579\n",
      "F1= 0.8389513108614232\n",
      "---------------------------------------------------------------------------------\n",
      "k= 29\n",
      "[[ 29  37]\n",
      " [  4 111]]\n",
      "Accuracy= 0.7734806629834254\n",
      "R= 0.9652173913043478\n",
      "P= 0.75\n",
      "F1= 0.8441064638783269\n",
      "---------------------------------------------------------------------------------\n",
      "k= 31\n",
      "[[ 26  40]\n",
      " [  2 113]]\n",
      "Accuracy= 0.7679558011049724\n",
      "R= 0.9826086956521739\n",
      "P= 0.738562091503268\n",
      "F1= 0.8432835820895521\n",
      "---------------------------------------------------------------------------------\n",
      "k= 33\n",
      "[[ 28  38]\n",
      " [  5 110]]\n",
      "Accuracy= 0.7624309392265194\n",
      "R= 0.9565217391304348\n",
      "P= 0.7432432432432432\n",
      "F1= 0.8365019011406843\n",
      "---------------------------------------------------------------------------------\n",
      "k= 35\n",
      "[[ 27  39]\n",
      " [  4 111]]\n",
      "Accuracy= 0.7624309392265194\n",
      "R= 0.9652173913043478\n",
      "P= 0.74\n",
      "F1= 0.8377358490566038\n",
      "---------------------------------------------------------------------------------\n",
      "k= 37\n",
      "[[ 27  39]\n",
      " [  4 111]]\n",
      "Accuracy= 0.7624309392265194\n",
      "R= 0.9652173913043478\n",
      "P= 0.74\n",
      "F1= 0.8377358490566038\n",
      "---------------------------------------------------------------------------------\n",
      "k= 39\n",
      "[[ 26  40]\n",
      " [  2 113]]\n",
      "Accuracy= 0.7679558011049724\n",
      "R= 0.9826086956521739\n",
      "P= 0.738562091503268\n",
      "F1= 0.8432835820895521\n",
      "---------------------------------------------------------------------------------\n",
      "k= 41\n",
      "[[ 26  40]\n",
      " [  2 113]]\n",
      "Accuracy= 0.7679558011049724\n",
      "R= 0.9826086956521739\n",
      "P= 0.738562091503268\n",
      "F1= 0.8432835820895521\n",
      "---------------------------------------------------------------------------------\n",
      "k= 43\n",
      "[[ 25  41]\n",
      " [  2 113]]\n",
      "Accuracy= 0.7624309392265194\n",
      "R= 0.9826086956521739\n",
      "P= 0.7337662337662337\n",
      "F1= 0.8401486988847584\n",
      "---------------------------------------------------------------------------------\n",
      "k= 45\n",
      "[[ 25  41]\n",
      " [  2 113]]\n",
      "Accuracy= 0.7624309392265194\n",
      "R= 0.9826086956521739\n",
      "P= 0.7337662337662337\n",
      "F1= 0.8401486988847584\n",
      "---------------------------------------------------------------------------------\n",
      "k= 47\n",
      "[[ 25  41]\n",
      " [  1 114]]\n",
      "Accuracy= 0.7679558011049724\n",
      "R= 0.991304347826087\n",
      "P= 0.7354838709677419\n",
      "F1= 0.8444444444444446\n",
      "---------------------------------------------------------------------------------\n",
      "k= 49\n",
      "[[ 24  42]\n",
      " [  1 114]]\n",
      "Accuracy= 0.7624309392265194\n",
      "R= 0.991304347826087\n",
      "P= 0.7307692307692307\n",
      "F1= 0.8413284132841328\n",
      "---------------------------------------------------------------------------------\n",
      "k= 51\n",
      "[[ 23  43]\n",
      " [  1 114]]\n",
      "Accuracy= 0.7569060773480663\n",
      "R= 0.991304347826087\n",
      "P= 0.7261146496815286\n",
      "F1= 0.8382352941176472\n",
      "---------------------------------------------------------------------------------\n",
      "k= 53\n",
      "[[ 24  42]\n",
      " [  1 114]]\n",
      "Accuracy= 0.7624309392265194\n",
      "R= 0.991304347826087\n",
      "P= 0.7307692307692307\n",
      "F1= 0.8413284132841328\n",
      "---------------------------------------------------------------------------------\n",
      "k= 55\n",
      "[[ 23  43]\n",
      " [  0 115]]\n",
      "Accuracy= 0.7624309392265194\n",
      "R= 1.0\n",
      "P= 0.7278481012658228\n",
      "F1= 0.8424908424908425\n",
      "---------------------------------------------------------------------------------\n",
      "k= 57\n",
      "[[ 22  44]\n",
      " [  0 115]]\n",
      "Accuracy= 0.7569060773480663\n",
      "R= 1.0\n",
      "P= 0.7232704402515723\n",
      "F1= 0.8394160583941604\n",
      "---------------------------------------------------------------------------------\n",
      "k= 59\n",
      "[[ 21  45]\n",
      " [  0 115]]\n",
      "Accuracy= 0.7513812154696132\n",
      "R= 1.0\n",
      "P= 0.71875\n",
      "F1= 0.8363636363636363\n",
      "---------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier #KNN套件\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "#嘗試每次以不同鄰居數量決定testing文章的漲跌標記\n",
    "accuracy = []\n",
    "TN = []\n",
    "FP = []\n",
    "FN = []\n",
    "TP = []\n",
    "\n",
    "k_cnt = [1,3,5,7,9,11,13, 15,17,19,21,23,25,27,29,31,33,35,37,39,41,43,45,47,49,51,53,55,57,59] #KNN存取幾個鄰居的數量\n",
    "for i in k_cnt:\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train,y_train) #將training set給KNN套件建出模型\n",
    "    pred = knn.predict(X_test) #將文章的testing set讀入模型中並決定文章的漲跌標記\n",
    "#     %matplotlib inline\n",
    "#     class_names=[0,1] # name of classes\n",
    "#     fig, ax = plt.subplots()\n",
    "#     tick_marks = np.arange(len(class_names))\n",
    "#     plt.xticks(tick_marks, class_names)\n",
    "#     plt.yticks(tick_marks, class_names)\n",
    "#     # create heatmap\n",
    "#     matrix = confusion_matrix(y_test,pred)\n",
    "#     sns.heatmap(pd.DataFrame(matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "#     ax.xaxis.set_label_position(\"top\")\n",
    "#     plt.tight_layout()\n",
    "#     plt.title('Confusion matrix', y=1.1)\n",
    "#     plt.ylabel('Actual label')\n",
    "#     plt.xlabel('Predicted label')\n",
    "    print('k=', i)\n",
    "#     print(pred)\n",
    "    print(confusion_matrix(y_test,pred))\n",
    "    print(\"Accuracy=\", accuracy_score(y_test, pred))\n",
    "    print('R=',metrics.recall_score(y_test, pred))\n",
    "    print('P=',metrics.precision_score(y_test, pred))\n",
    "    print('F1=',metrics.f1_score(y_test, pred))\n",
    "    print(\"---------------------------------------------------------------------------------\")\n",
    "    accuracy.append(accuracy_score(y_test, pred))\n",
    "    TN.append(confusion_matrix(y_test,pred)[0][0])\n",
    "    FP.append(confusion_matrix(y_test,pred)[0][1])\n",
    "    FN.append(confusion_matrix(y_test,pred)[1][0])\n",
    "    TP.append(confusion_matrix(y_test,pred)[1][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "Output_result = {\"K\":k_cnt, \"accuracy\":accuracy, \"TN\":TN, \"FP\":FP, \"FN\":FN, \"TP\":TP}\n",
    "Output = pd.DataFrame(Output_result)\n",
    "Output.to_csv(\"KNNresult.csv\", encoding = \"utf_8_sig\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
